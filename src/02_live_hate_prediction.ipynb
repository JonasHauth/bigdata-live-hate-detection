{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Local Spark Environment (3.3.1)\n",
    "- 4 Cores, 8 Threats (1.8 Ghz Base Clock)\n",
    "- 8 GB RAM (shared with OS)\n",
    "- SSD "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durchlaufen der Systems der Daten\n",
    "1. Einlesen der Daten\n",
    "2. Erstellen eines Lesestroms für die Daten, mit maximal 2 Dateien pro Trigger\n",
    "3. Durchlaufen der Interferenzpipeline\n",
    "\n",
    "Pfade:\n",
    "Memory-bound: Bearbeiten der Daten im Zwischenspeicher (RAM)\n",
    "CPU-bound: Mit allen Daten im RAM sind wir CPU-Bound\n",
    "\n",
    "Skalierung: \n",
    "Unsere Anwendung ist noch nicht für die Verarbeitung von Big Data skaliert, da sie auf einem einzelnen lokalen System ausgeführt wird (Local Mode). Erst wenn die Menge an Daten, größer als der verfügbare Arbeitsspeicher des lokalen Systems ist, werden die Leistungsprobleme und Out-of-Memory-Fehler auftreten.\n",
    "\n",
    "Was passiert wenn die Datenmengen größenordnungsmäßig zunehmen? (1x/10x/100x... oder 2x/4x/8x/16x/...)?\n",
    "- Erhöhte Verarbeitungsleistung: Das Upscaling der Live-Analyse erfordert in der Regel eine höhere Verarbeitungsleistung, da mehr Daten in Echtzeit analysiert werden müssen. Dies führt zu dem Einsatz von mehr oder leistungsfähigerer Hardware. Hierbei ist zu beachten dass eine horizontale Skalierung effizienter ist.\n",
    "- Erhöhte Speicherkapazität: Das Upscaling der Live-Analyse erfordert auch mehr Speicherkapazität, um die zusätzlichen Daten zu speichern, die analysiert werden. Dies könnte die Verwendung größerer Festplatten oder zusätzlicher Speichersysteme bedeuten.\n",
    "- Erhöhte Bandbreite: Die Hochskalierung der Live-Feed-Datenanalyse erfordert möglicherweise mehr Bandbreite für die Übertragung der zusätzlichen Daten, die analysiert werden. Dies kann zu einem Problem werden, wenn die Netzwerkinfrastruktur nicht in der Lage ist, die erhöhte Last zu bewältigen.\n",
    "\n",
    "Was passiert wenn die Anfragen oder Abfragen größenordnungsmäßig zunehmen oder die Latenzbedingungen größenordnungsmäßig abnehmen?\n",
    "- Erhöhte Verarbeitungszeit: Wenn die Anfragen oder Abfragen größer werden, kann ihre Verarbeitung länger dauern, da mehr Daten zu analysieren sind. Dies kann zu erhöhten Latenzzeiten und einer insgesamt langsameren Leistung führen.\n",
    "- Erhöhte Ressourcennutzung: Größere Anfragen oder Abfragen erfordern unter Umständen auch mehr Ressourcen, z. B. Verarbeitungsleistung, Arbeitsspeicher und Speicherplatz, um verarbeitet zu werden. Dies kann zu einer erhöhten Ressourcennutzung führen und möglicherweise die Leistung anderer Aufgaben oder Prozesse, die gleichzeitig laufen, beeinträchtigen.\n",
    "- Geringere Leistung: Wenn die Latenzbedingungen abnehmen, kann es schwieriger werden, Anfragen oder Abfragen in Echtzeit zu verarbeiten, da weniger Zeit für die Verarbeitung der Daten zur Verfügung steht. Dies kann zu einer verringerten Leistung und möglicherweise zu verpassten Analysemöglichkeiten führen.\n",
    "- Erhöhte Komplexität: Sowohl größere Anfragen oder Abfragen als auch geringere Latenzzeiten können die Datenanalyse komplexer machen, da mehr Daten zu verarbeiten sind und weniger Zeit zur Verfügung steht. Dies kann den Einsatz fortschrittlicherer Algorithmen oder Techniken erforderlich machen, um das größere Datenvolumen zu bewältigen und die Echtzeitverarbeitungsanforderungen zu erfüllen.\n",
    "\n",
    "Welche Pfade sind einfach/schwieriger Skalierbar?\n",
    "- Datenerfassung: Einfache Skalierbarkeit, da weitere Server hinzugefügt werden können, um die erhöhte Last zu bewältigen und mehr Daten von der Twitter-API zu sammeln.\n",
    "- Datenbereinigung: Aktueller Prozess zur Datenbereinigung relativ simpel (entfernen von Sonderzeichen, Kleinschreibung, etc.) somit kann der Pfad gut skalieren.\n",
    "- Datenumwandlung: Aktuell ist die Datenumwandlung noch simpel, und das System kann gut skalieren. Falls die Datenumwandlung  jedoch komplexer werden sollte (Maschine Learning, Erkennen von Text in Bildern/Audio konvertieren in Text, etc.). würden würde das die Skalierung erheblich schwieriger machen.\n",
    "- Modellinterferenz: Skaliert gut, da nur ein begrenzter Datensatz für das Training genommen werden kann, welcher gelabelt wurde. \n",
    "- Datenspeicherung: Dieser Schritt ist relativ einfach zu skalieren, da weitere Server hinzugefügt werden können, um die erhöhte Last zu bewältigen, und die Daten auf die Server verteilt werden können.\n",
    "\n",
    "Dimensionen Zielsystem Prototyp:\n",
    "- Speicheranforderungen: Speichern Nur Text: 15 GB/Tag -> = 5 TB/Jahr\n",
    "Redundanz -> RF = 3 -> = 15 TB /Jahr -> 8 Festplatten a 2 TB -> 1 Unit\n",
    "- CPU Anforderungen: 4 Kerne mit 8 Threats (1.8 Ghz Base Clock) = 2000 Tweets/ Sekunde\n",
    "Höchstleistung = 10 000 Tweets / Sekunde\n",
    "Abdeckung von Systemausfällen und Anstieg der Nutzer = 20 000 Tweets/ Sekunden -> 40 Kerne mit 8 Threats (1.8 Ghz Base Clock)\n",
    "\n",
    "Dimensionen Zielsystem kommerzielles System:\n",
    "- CPU Anforderungen\n",
    "Prototyp: 4 Kerne mit 8 Threats (1.8 Ghz Base Clock) = 2000 Tweets/ Sekunde\n",
    "Anforderung: Durchschnitt 6000 Tweets/ Sekunde\n",
    "Höchster Messtand: 10 000 Tweets/ Sekunde\n",
    "Abdeckung von Systemausällen = 20 000 Tweets/ Sekunden\n",
    "Weiterentwicklung des Systems (Analyse von Videos, Bilder, andere Sprachen, etc.)\n",
    "->x25 Prototypleistung Leistung\n",
    "1000 Kerne mit 8 Threats (1.8 Ghz Base Clock)\n",
    "- Speicher Anforderung\n",
    "Twitter Daten Upload 12 TB/Tag\n",
    "->4.5 PB/Jahr\n",
    "45Unit x 8 Festplatten (2TB) = 720 TB\n",
    " -> 3 Racks a 45 Units für 1 Jahr\n",
    "\n",
    "\n",
    "Fehler in der Analyse: \n",
    "-  Implementierung von Mechanismen zur Behandlung von Ausnahmen im Code, z. B. Try-Except-Blöcke\n",
    "-  Implementierung eines Meldesystems und die manuelle Überprüfung der Fehler können die Falsch-Positiv sowie Falsch-Negativen Ereignisse behoben werden\n",
    "\n",
    "Fehlertoleranz verteiltes System: \n",
    "- DataFrame wird zur Fehlertoleranz über mehrere Knoten in einem Cluster repliziert. Dies trägt zur Fehlertoleranz im Falle von Knotenausfällen bei. Die verlorenen Daten können von den Replikaten wiederhergestellt werden.\n",
    "- Lineage Graph zur um verlorene Daten wiederherzustellen\n",
    "\n",
    "Daten Speicherung:\n",
    "- Twitter verwendet aktuell Hadoop-Cluster, auf denen Datenverarbeitung und HDFS laufen \n",
    " + Einfache Anbindung, Synergien\n",
    " - Geschwindigkeit ausreichend für Realtime analyse?\n",
    "\n",
    "Daten Codieung:\n",
    "- Unstrukturierte Daten, wie der Twitter Feed und Text-Dateien, können nicht direkt im Parquet-Format gespeichert werden. Es gibt jedoch die Möglichkeit, unstrukturierte Daten zu kodieren oder zu transformieren, um sie in Parquet zu speichern.\n",
    "- Daten werden in ein strukturiertes Format konvertieren (JSON), dieses wird dann in Parquet gespeichert \n",
    "- Prozess der Kodierung:\n",
    "    1. Serialisierung: Die Twitter-Feed-Daten müssen in ein Format serialisiert werden, das auf die Festplatte geschrieben werden kann.\n",
    "    2. Auf die Festplatte schreiben: Die serialisierten Twitter-Feed-Daten können unter Verwendung des Parquet-Dateiformats auf die Festplatte geschrieben werden.\n",
    "    3. Von der Festplatte lesen: Die serialisierten Twitter-Feed-Daten können mit Hilfe der PySpark-API von der Festplatte zurückgelesen werden.\n",
    "    4. Deserialisierung: Die Twitter-Feed-Daten können wieder in ihr ursprüngliches Format deserialisiert werden. Dies kann mit derselben Bibliothek geschehen, die für die Serialisierung verwendet wurde.\n",
    "\n",
    "Abkürzungen des Prototyps:\n",
    "- Limitierte Integration in Systemlandschaft\n",
    "- Keine Analye von Videos, Bildern und Tonspuren\n",
    "- Sentiment Analyse nur auf Englisch\n",
    "- Tainingsdatensatz ist limietiert.\n",
    "\n",
    "Echtzeitfähigkeit des Prototyps:\n",
    "Durch 4 Kerne mit 8 Threats (1.8 Ghz Base Clock) führt zu einem Durchsatz von 2000 Tweets/Sekunde. Dies stellt bereits einen erheblichen Anteil dar, wenn man dies mit den durchschnittlichen Menge von 6000 Tweets/ Sekunde vergleicht. Jedoch handelt es sich hierbei um Tweets in reiner Textform. Für eine Live-Analyse, mit Metadaten sowie Tweets welche Bilder und Ton beinhalten,müsste das System ausgebaut werden. Dies könnte bspw. anhand von Spark Streaming mit einer horizontalen Skalierung durchgeführt werden.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apache Spark version:  3.3.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Jonas-Surface:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>multi_class_text_classifiter</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x206465f7070>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.sql.functions import col, regexp_replace, lower\n",
    "import os\n",
    "\n",
    "\n",
    "MAX_MEMORY = \"6g\"\n",
    "spark = SparkSession.builder \\\n",
    "                    .appName('live_hate_prediction')\\\n",
    "                    .master(\"local[*]\") \\\n",
    "                    .config(\"spark.executor.memory\", MAX_MEMORY) \\\n",
    "                    .config(\"spark.driver.memory\", MAX_MEMORY) \\\n",
    "                    .config(\"spark.jars.packages\", \"org.apache.spark:spark-avro_2.12:3.3.1\") \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "print(\"Apache Spark version: \", spark.version)\n",
    "spark"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming Source\n",
    "Als Streaming-Quelle für den Prototyp nutzen wir das lokale Filesystem. Hier haben wir ca. 4 Mio. ungesehene Tweets, welche auf Hate-Nachrichten überprüft werden sollen. \n",
    "Dafür sind die Tweets mit Metadaten im Parquet-Format gespeichert (ca 5 GB Rohdaten).\n",
    "Folgende Schritte sind hierfür notwendig:\n",
    "- Einlesen des Daten-Schemas\n",
    "- Erstellen eines ReadStreams auf den Daten (die maximale Anzahl der Files pro Trigger wird auf zwei begrenzt.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Anzahl der Partitions: 10\n"
     ]
    }
   ],
   "source": [
    "spark_df = spark.read.parquet('C://data/twitter-stream-parquet-medium/')\n",
    "dataSchema = spark_df.schema\n",
    "\n",
    "print(f\" Anzahl der Partitions: {spark_df.rdd.getNumPartitions()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming = spark.readStream.schema(dataSchema).option(\"maxFilesPerTrigger\", 2).parquet('C://data/twitter-stream-parquet-medium/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferenz Pipeline laden\n",
    "- Die zuvor erstelle Inferenzpipeline wird in den Hauptspeichergeladen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_pipeline = PipelineModel.load(\"../models/mllib_model_nb\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Processing\n",
    "\n",
    "Die Daten werden in Batches unterteilt und jeder Batch wird einzeln und parallel mit den Sparkoperationen verarbeitet. Die Ergebnisse der einzelnen Batches werden zum Endergebnis kombiniert. \n",
    "\n",
    "Folgende Methoden werden auf den Daten ausgeführt:\n",
    "- Submethode clean_text wird auf jedem Micro-Batch ausgeführt und bereinigt die Texte (z.B. Groß- und Kleinschreibung, Sondernzeichen, ...)\n",
    "- Methode batch_hate_interference wird auf jedem Micro-Batch ausgeführt und ruft Submethode clean_text auf, führt die Inferenz-Pipeline aus und speichert die identifizierten Hate-Tweets zur weiteren Verarbeitung. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(c):\n",
    "  c = lower(c)\n",
    "  c = regexp_replace(c, \"(https?\\://)\\S+\", \"\") # Remove links\n",
    "  c = regexp_replace(c, \"(\\\\n)|\\n|\\r|\\t\", \"\") # Remove CR, tab, and LR\n",
    "  c = regexp_replace(c, \"(?:(?:[0-9]{2}[:\\/,]){2}[0-9]{2,4})\", \"\") # Remove dates\n",
    "  c = regexp_replace(c, \"@([A-Za-z0-9_]+)\", \"\") # Remove usernames\n",
    "  c = regexp_replace(c, \"[0-9]\", \"\") # Remove numbers\n",
    "  c = regexp_replace(c, \"\\:|\\/|\\#|\\.|\\?|\\!|\\&|\\\"|\\,\", \"\") # Remove symbols\n",
    "  return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_hate_inference(df, test):\n",
    "\n",
    "    print(f'Iter: {test}')\n",
    "\n",
    "    # Clean Text Columns\n",
    "    df = df.withColumn(\"text\", clean_text(col(\"text\")))\n",
    "\n",
    "    # Predict on Batch\n",
    "    final_df = trained_pipeline.transform(df).select('text','prediction')\n",
    "\n",
    "    # Handling for data (Save Hate Speech)\n",
    "    hate = final_df.filter(final_df['prediction'] == 1.0)\n",
    "    hate.write.mode('append').parquet('../data/parquet_output')\n",
    "    times_hate = hate.count()\n",
    "    print(f'Times hate detected: {times_hate}')\n",
    "\n",
    "    not_hate = final_df.filter(final_df['prediction'] == 0.0)\n",
    "    times_not_hate = not_hate.count()\n",
    "    print(f'Times not hate detected: {times_not_hate}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Streaming-Methoden Foreach und ForeachBatch ermöglichen, dass eigene Logik auf den Stream ausgeführt werden kann. \n",
    "    - Trigger: availableNow ist nur für den Demo-Modus, beendet den Stream nachdem alle Verfügbaren Daten abgearbeitet wurden.\n",
    "    - Start: Beginnt Ausführung "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0\n",
      "Times hate detected: 202\n",
      "Times not hate detected: 4920\n",
      "Iter: 1\n",
      "Times hate detected: 204\n",
      "Times not hate detected: 4686\n",
      "Iter: 2\n",
      "Times hate detected: 209\n",
      "Times not hate detected: 4876\n",
      "Iter: 3\n",
      "Times hate detected: 223\n",
      "Times not hate detected: 4987\n",
      "Iter: 4\n",
      "Times hate detected: 181\n",
      "Times not hate detected: 4632\n"
     ]
    }
   ],
   "source": [
    "batchHateInference = streaming.writeStream.foreachBatch(batch_hate_inference).trigger(availableNow=True).start() #"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daten zu Diagnose und Protokoll der Ausführung:\n",
    "- Mit dem aktuellen Setup (lokales Spark) können ca. 2000 Tweets / Sekunde untersucht werden.\n",
    "- Durch Spark Streaming kann der Workload horizontal skaliert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '8ff70e78-1df3-4525-9d3b-8fcdbdb6512f',\n",
       "  'runId': '63858400-bdc1-4521-b96c-67bc42663c92',\n",
       "  'name': None,\n",
       "  'timestamp': '2022-12-20T14:56:33.731Z',\n",
       "  'batchId': 0,\n",
       "  'numInputRows': 15366,\n",
       "  'inputRowsPerSecond': 0.0,\n",
       "  'processedRowsPerSecond': 1895.1652688702516,\n",
       "  'durationMs': {'addBatch': 6601,\n",
       "   'getBatch': 88,\n",
       "   'latestOffset': 440,\n",
       "   'queryPlanning': 33,\n",
       "   'triggerExecution': 8108,\n",
       "   'walCommit': 396},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'FileStreamSource[file:/C:/data/twitter-stream-parquet-medium]',\n",
       "    'startOffset': None,\n",
       "    'endOffset': {'logOffset': 0},\n",
       "    'latestOffset': None,\n",
       "    'numInputRows': 15366,\n",
       "    'inputRowsPerSecond': 0.0,\n",
       "    'processedRowsPerSecond': 1895.1652688702516}],\n",
       "  'sink': {'description': 'ForeachBatchSink', 'numOutputRows': -1}},\n",
       " {'id': '8ff70e78-1df3-4525-9d3b-8fcdbdb6512f',\n",
       "  'runId': '63858400-bdc1-4521-b96c-67bc42663c92',\n",
       "  'name': None,\n",
       "  'timestamp': '2022-12-20T14:56:41.840Z',\n",
       "  'batchId': 1,\n",
       "  'numInputRows': 14670,\n",
       "  'inputRowsPerSecond': 1809.1009988901221,\n",
       "  'processedRowsPerSecond': 2156.401587534911,\n",
       "  'durationMs': {'addBatch': 5665,\n",
       "   'getBatch': 63,\n",
       "   'latestOffset': 343,\n",
       "   'queryPlanning': 5,\n",
       "   'triggerExecution': 6803,\n",
       "   'walCommit': 327},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'FileStreamSource[file:/C:/data/twitter-stream-parquet-medium]',\n",
       "    'startOffset': {'logOffset': 0},\n",
       "    'endOffset': {'logOffset': 1},\n",
       "    'latestOffset': None,\n",
       "    'numInputRows': 14670,\n",
       "    'inputRowsPerSecond': 1809.1009988901221,\n",
       "    'processedRowsPerSecond': 2156.401587534911}],\n",
       "  'sink': {'description': 'ForeachBatchSink', 'numOutputRows': -1}},\n",
       " {'id': '8ff70e78-1df3-4525-9d3b-8fcdbdb6512f',\n",
       "  'runId': '63858400-bdc1-4521-b96c-67bc42663c92',\n",
       "  'name': None,\n",
       "  'timestamp': '2022-12-20T14:56:48.643Z',\n",
       "  'batchId': 2,\n",
       "  'numInputRows': 15255,\n",
       "  'inputRowsPerSecond': 2242.393061884463,\n",
       "  'processedRowsPerSecond': 2236.1477572559365,\n",
       "  'durationMs': {'addBatch': 5630,\n",
       "   'getBatch': 64,\n",
       "   'latestOffset': 361,\n",
       "   'queryPlanning': 5,\n",
       "   'triggerExecution': 6822,\n",
       "   'walCommit': 324},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'FileStreamSource[file:/C:/data/twitter-stream-parquet-medium]',\n",
       "    'startOffset': {'logOffset': 1},\n",
       "    'endOffset': {'logOffset': 2},\n",
       "    'latestOffset': None,\n",
       "    'numInputRows': 15255,\n",
       "    'inputRowsPerSecond': 2242.393061884463,\n",
       "    'processedRowsPerSecond': 2236.1477572559365}],\n",
       "  'sink': {'description': 'ForeachBatchSink', 'numOutputRows': -1}},\n",
       " {'id': '8ff70e78-1df3-4525-9d3b-8fcdbdb6512f',\n",
       "  'runId': '63858400-bdc1-4521-b96c-67bc42663c92',\n",
       "  'name': None,\n",
       "  'timestamp': '2022-12-20T14:56:55.466Z',\n",
       "  'batchId': 3,\n",
       "  'numInputRows': 15630,\n",
       "  'inputRowsPerSecond': 2290.7811812985487,\n",
       "  'processedRowsPerSecond': 2330.0536672629696,\n",
       "  'durationMs': {'addBatch': 5540,\n",
       "   'getBatch': 64,\n",
       "   'latestOffset': 378,\n",
       "   'queryPlanning': 7,\n",
       "   'triggerExecution': 6708,\n",
       "   'walCommit': 335},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'FileStreamSource[file:/C:/data/twitter-stream-parquet-medium]',\n",
       "    'startOffset': {'logOffset': 2},\n",
       "    'endOffset': {'logOffset': 3},\n",
       "    'latestOffset': None,\n",
       "    'numInputRows': 15630,\n",
       "    'inputRowsPerSecond': 2290.7811812985487,\n",
       "    'processedRowsPerSecond': 2330.0536672629696}],\n",
       "  'sink': {'description': 'ForeachBatchSink', 'numOutputRows': -1}},\n",
       " {'id': '8ff70e78-1df3-4525-9d3b-8fcdbdb6512f',\n",
       "  'runId': '63858400-bdc1-4521-b96c-67bc42663c92',\n",
       "  'name': None,\n",
       "  'timestamp': '2022-12-20T14:57:02.175Z',\n",
       "  'batchId': 4,\n",
       "  'numInputRows': 14439,\n",
       "  'inputRowsPerSecond': 2152.183633924579,\n",
       "  'processedRowsPerSecond': 2000.4156275976725,\n",
       "  'durationMs': {'addBatch': 5929,\n",
       "   'getBatch': 66,\n",
       "   'latestOffset': 365,\n",
       "   'queryPlanning': 4,\n",
       "   'triggerExecution': 7218,\n",
       "   'walCommit': 343},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'FileStreamSource[file:/C:/data/twitter-stream-parquet-medium]',\n",
       "    'startOffset': {'logOffset': 3},\n",
       "    'endOffset': {'logOffset': 4},\n",
       "    'latestOffset': None,\n",
       "    'numInputRows': 14439,\n",
       "    'inputRowsPerSecond': 2152.183633924579,\n",
       "    'processedRowsPerSecond': 2000.4156275976725}],\n",
       "  'sink': {'description': 'ForeachBatchSink', 'numOutputRows': -1}}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchHateInference.recentProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Stopped', 'isDataAvailable': False, 'isTriggerActive': False}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchHateInference.status"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folgende Tweets wurden durch das Modell als Hate-Speech identifiziert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       rt  a power top and a perfect cumdump  it's al...\n",
       "1                rt  le cogi un amor cb a estar en casa 🥰\n",
       "2       rt  in the conversation about student loans on...\n",
       "3       nossa vc fica nervosa com tudo  claro não tenh...\n",
       "4       bad guys was such a funny movie i highly recom...\n",
       "                              ...                        \n",
       "2033                                         rt  tan tit \n",
       "2034    rt  amei te conhecer  vc me ensinou mta coisa ...\n",
       "2035    rt  raise your hand if you think antifa should...\n",
       "2036                                              natasha\n",
       "2037      fair enough at least you’re honest about hav...\n",
       "Name: text, Length: 2038, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detected_hate_df = spark.read.parquet('../data/parquet_output')\n",
    "hate_texts = detected_hate_df.select('text').toPandas()['text']\n",
    "hate_texts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Anzahl der Partitions: 10\n"
     ]
    }
   ],
   "source": [
    "spark_df = spark.read.parquet('C://data/twitter-stream-parquet-medium/')\n",
    "dataSchema = spark_df.schema\n",
    "\n",
    "print(f\" Anzahl der Partitions: {spark_df.rdd.getNumPartitions()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming = spark.readStream.schema(dataSchema).option(\"maxFilesPerTrigger\", 2).parquet('C://data/twitter-stream-parquet-medium/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def live_hate_inference(row):\n",
    "\n",
    "    # text = row[['text']]\n",
    "    \n",
    "    df = row.toDF()\n",
    "    df.write.mode('append').parquet('../data/parquet_live_output')\n",
    "\n",
    "    #spark.write.mode('append').parquet('../data/hate_detected')\n",
    "\n",
    "    # df = df.withColumn(\"text\", clean_text(col(\"text\")))\n",
    "\n",
    "    # wordsDataFrame_transformed = prep_trained_pipeline.transform(df)\n",
    "    # final_df = model_trained_pipeline.transform(wordsDataFrame_transformed).select('text','prediction')\n",
    "    \n",
    "    # times_hate = final_df.filter(final_df['prediction'] == 1.0).count()\n",
    "    # print(f'Times hate detected: {times_hate}')\n",
    "    # times_not_hate = final_df.filter(final_df['prediction'] == 0.0).count()\n",
    "    # print(f'Times not hate detected: {times_not_hate}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = streaming.writeStream.foreach(live_hate_inference).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Terminated with exception: Writing job aborted',\n",
       " 'isDataAvailable': False,\n",
       " 'isTriggerActive': False}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.recentProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.utils.StreamingQueryException('Writing job aborted\\n=== Streaming Query ===\\nIdentifier: [id = 50edd787-588c-46e6-9500-7a7a714de56c, runId = 1756f553-dbb2-487c-bc77-afac52b7d38d]\\nCurrent Committed Offsets: {}\\nCurrent Available Offsets: {FileStreamSource[file:/C:/data/twitter-stream-parquet-medium]: {\"logOffset\":0}}\\n\\nCurrent State: ACTIVE\\nThread State: RUNNABLE\\n\\nLogical Plan:\\nWriteToMicroBatchDataSource ForeachWriterTable(org.apache.spark.sql.execution.python.PythonForeachWriter@41cc0171,Right(org.apache.spark.sql.execution.streaming.sources.ForeachWriterTable$$$Lambda$4160/417186086@15026d32)), 50edd787-588c-46e6-9500-7a7a714de56c, Append\\n+- StreamingExecutionRelation FileStreamSource[file:/C:/data/twitter-stream-parquet-medium], [contributors#18549, coordinates#18550, created_at#18551, display_text_range#18552, entities#18553, extended_entities#18554, extended_tweet#18555, favorite_count#18556L, favorited#18557, filter_level#18558, geo#18559, id#18560L, id_str#18561, in_reply_to_screen_name#18562, in_reply_to_status_id#18563L, in_reply_to_status_id_str#18564, in_reply_to_user_id#18565L, in_reply_to_user_id_str#18566, is_quote_status#18567, lang#18568, place#18569, possibly_sensitive#18570, quote_count#18571L, quoted_status#18572, ... 13 more fields]\\n',\n",
       "                                          'org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:330)\\n\\t at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:208)',\n",
       "                                          JavaObject id=o3037)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.exception()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test other approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming = spark.readStream.schema(dataSchema).option(\"maxFilesPerTrigger\", 2).parquet('C://data/twitter-stream-parquet-medium/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "testModel = trained_pipeline.transform(streaming).select('text','prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = testModel.writeStream.format(\"parquet\").option('path', '../data/parquet_output/').option(\"checkpointLocation\", \"../data/checkpoints/\").start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Waiting for data to arrive',\n",
       " 'isDataAvailable': False,\n",
       " 'isTriggerActive': False}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '84a5b1f4-2ce0-4666-96d4-9b0344d19233',\n",
       "  'runId': 'c0c536a0-f8a3-48be-9291-f9d39a6920fb',\n",
       "  'name': None,\n",
       "  'timestamp': '2022-12-20T18:30:14.163Z',\n",
       "  'batchId': 0,\n",
       "  'numInputRows': 5122,\n",
       "  'inputRowsPerSecond': 0.0,\n",
       "  'processedRowsPerSecond': 1958.699808795411,\n",
       "  'durationMs': {'addBatch': 1056,\n",
       "   'getBatch': 69,\n",
       "   'latestOffset': 457,\n",
       "   'queryPlanning': 26,\n",
       "   'triggerExecution': 2615,\n",
       "   'walCommit': 577},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'FileStreamSource[file:/C:/data/twitter-stream-parquet-medium]',\n",
       "    'startOffset': None,\n",
       "    'endOffset': {'logOffset': 0},\n",
       "    'latestOffset': None,\n",
       "    'numInputRows': 5122,\n",
       "    'inputRowsPerSecond': 0.0,\n",
       "    'processedRowsPerSecond': 1958.699808795411}],\n",
       "  'sink': {'description': 'FileSink[../data/parquet_output/]',\n",
       "   'numOutputRows': -1}},\n",
       " {'id': '84a5b1f4-2ce0-4666-96d4-9b0344d19233',\n",
       "  'runId': 'c0c536a0-f8a3-48be-9291-f9d39a6920fb',\n",
       "  'name': None,\n",
       "  'timestamp': '2022-12-20T18:30:16.779Z',\n",
       "  'batchId': 1,\n",
       "  'numInputRows': 4890,\n",
       "  'inputRowsPerSecond': 1869.2660550458716,\n",
       "  'processedRowsPerSecond': 838.0462724935733,\n",
       "  'durationMs': {'addBatch': 4335,\n",
       "   'getBatch': 104,\n",
       "   'latestOffset': 384,\n",
       "   'queryPlanning': 18,\n",
       "   'triggerExecution': 5835,\n",
       "   'walCommit': 469},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'FileStreamSource[file:/C:/data/twitter-stream-parquet-medium]',\n",
       "    'startOffset': {'logOffset': 0},\n",
       "    'endOffset': {'logOffset': 1},\n",
       "    'latestOffset': None,\n",
       "    'numInputRows': 4890,\n",
       "    'inputRowsPerSecond': 1869.2660550458716,\n",
       "    'processedRowsPerSecond': 838.0462724935733}],\n",
       "  'sink': {'description': 'FileSink[../data/parquet_output/]',\n",
       "   'numOutputRows': -1}},\n",
       " {'id': '84a5b1f4-2ce0-4666-96d4-9b0344d19233',\n",
       "  'runId': 'c0c536a0-f8a3-48be-9291-f9d39a6920fb',\n",
       "  'name': None,\n",
       "  'timestamp': '2022-12-20T18:30:22.616Z',\n",
       "  'batchId': 2,\n",
       "  'numInputRows': 5085,\n",
       "  'inputRowsPerSecond': 871.1666952201474,\n",
       "  'processedRowsPerSecond': 1784.2105263157894,\n",
       "  'durationMs': {'addBatch': 1136,\n",
       "   'getBatch': 124,\n",
       "   'latestOffset': 582,\n",
       "   'queryPlanning': 33,\n",
       "   'triggerExecution': 2850,\n",
       "   'walCommit': 507},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'FileStreamSource[file:/C:/data/twitter-stream-parquet-medium]',\n",
       "    'startOffset': {'logOffset': 1},\n",
       "    'endOffset': {'logOffset': 2},\n",
       "    'latestOffset': None,\n",
       "    'numInputRows': 5085,\n",
       "    'inputRowsPerSecond': 871.1666952201474,\n",
       "    'processedRowsPerSecond': 1784.2105263157894}],\n",
       "  'sink': {'description': 'FileSink[../data/parquet_output/]',\n",
       "   'numOutputRows': -1}},\n",
       " {'id': '84a5b1f4-2ce0-4666-96d4-9b0344d19233',\n",
       "  'runId': 'c0c536a0-f8a3-48be-9291-f9d39a6920fb',\n",
       "  'name': None,\n",
       "  'timestamp': '2022-12-20T18:30:25.467Z',\n",
       "  'batchId': 3,\n",
       "  'numInputRows': 5210,\n",
       "  'inputRowsPerSecond': 1827.4289722904243,\n",
       "  'processedRowsPerSecond': 1961.5963855421685,\n",
       "  'durationMs': {'addBatch': 1035,\n",
       "   'getBatch': 93,\n",
       "   'latestOffset': 516,\n",
       "   'queryPlanning': 21,\n",
       "   'triggerExecution': 2656,\n",
       "   'walCommit': 548},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'FileStreamSource[file:/C:/data/twitter-stream-parquet-medium]',\n",
       "    'startOffset': {'logOffset': 2},\n",
       "    'endOffset': {'logOffset': 3},\n",
       "    'latestOffset': None,\n",
       "    'numInputRows': 5210,\n",
       "    'inputRowsPerSecond': 1827.4289722904243,\n",
       "    'processedRowsPerSecond': 1961.5963855421685}],\n",
       "  'sink': {'description': 'FileSink[../data/parquet_output/]',\n",
       "   'numOutputRows': -1}},\n",
       " {'id': '84a5b1f4-2ce0-4666-96d4-9b0344d19233',\n",
       "  'runId': 'c0c536a0-f8a3-48be-9291-f9d39a6920fb',\n",
       "  'name': None,\n",
       "  'timestamp': '2022-12-20T18:30:28.124Z',\n",
       "  'batchId': 4,\n",
       "  'numInputRows': 4813,\n",
       "  'inputRowsPerSecond': 1811.441475348137,\n",
       "  'processedRowsPerSecond': 1316.8262653898769,\n",
       "  'durationMs': {'addBatch': 1517,\n",
       "   'getBatch': 114,\n",
       "   'latestOffset': 723,\n",
       "   'queryPlanning': 25,\n",
       "   'triggerExecution': 3655,\n",
       "   'walCommit': 796},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'FileStreamSource[file:/C:/data/twitter-stream-parquet-medium]',\n",
       "    'startOffset': {'logOffset': 3},\n",
       "    'endOffset': {'logOffset': 4},\n",
       "    'latestOffset': None,\n",
       "    'numInputRows': 4813,\n",
       "    'inputRowsPerSecond': 1811.441475348137,\n",
       "    'processedRowsPerSecond': 1316.8262653898769}],\n",
       "  'sink': {'description': 'FileSink[../data/parquet_output/]',\n",
       "   'numOutputRows': -1}},\n",
       " {'id': '84a5b1f4-2ce0-4666-96d4-9b0344d19233',\n",
       "  'runId': 'c0c536a0-f8a3-48be-9291-f9d39a6920fb',\n",
       "  'name': None,\n",
       "  'timestamp': '2022-12-20T18:30:41.777Z',\n",
       "  'batchId': 5,\n",
       "  'numInputRows': 0,\n",
       "  'inputRowsPerSecond': 0.0,\n",
       "  'processedRowsPerSecond': 0.0,\n",
       "  'durationMs': {'latestOffset': 21, 'triggerExecution': 21},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'FileStreamSource[file:/C:/data/twitter-stream-parquet-medium]',\n",
       "    'startOffset': {'logOffset': 4},\n",
       "    'endOffset': {'logOffset': 4},\n",
       "    'latestOffset': None,\n",
       "    'numInputRows': 0,\n",
       "    'inputRowsPerSecond': 0.0,\n",
       "    'processedRowsPerSecond': 0.0}],\n",
       "  'sink': {'description': 'FileSink[../data/parquet_output/]',\n",
       "   'numOutputRows': -1}},\n",
       " {'id': '84a5b1f4-2ce0-4666-96d4-9b0344d19233',\n",
       "  'runId': 'c0c536a0-f8a3-48be-9291-f9d39a6920fb',\n",
       "  'name': None,\n",
       "  'timestamp': '2022-12-20T18:30:51.811Z',\n",
       "  'batchId': 5,\n",
       "  'numInputRows': 0,\n",
       "  'inputRowsPerSecond': 0.0,\n",
       "  'processedRowsPerSecond': 0.0,\n",
       "  'durationMs': {'latestOffset': 14, 'triggerExecution': 14},\n",
       "  'stateOperators': [],\n",
       "  'sources': [{'description': 'FileStreamSource[file:/C:/data/twitter-stream-parquet-medium]',\n",
       "    'startOffset': {'logOffset': 4},\n",
       "    'endOffset': {'logOffset': 4},\n",
       "    'latestOffset': None,\n",
       "    'numInputRows': 0,\n",
       "    'inputRowsPerSecond': 0.0,\n",
       "    'processedRowsPerSecond': 0.0}],\n",
       "  'sink': {'description': 'FileSink[../data/parquet_output/]',\n",
       "   'numOutputRows': -1}}]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.recentProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rate Source Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a streaming DataFrame\n",
    "df = spark.readStream \\\n",
    "    .format(\"rate\") \\\n",
    "    .option(\"rowsPerSecond\", 10) \\\n",
    "    .load()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0 (v3.11.0:deaf509e8f, Oct 24 2022, 14:43:23) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_url</th>\n",
       "      <th>labels</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>labels_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1114679353714016256</th>\n",
       "      <td>http://pbs.twimg.com/tweet_video_thumb/D3gi9MH...</td>\n",
       "      <td>[4, 1, 3]</td>\n",
       "      <td>https://twitter.com/user/status/11146793537140...</td>\n",
       "      <td>@FriskDontMiss Nigga https://t.co/cAsaLWEpue</td>\n",
       "      <td>[Religion, Racist, Homophobe]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063020048816660480</th>\n",
       "      <td>http://pbs.twimg.com/ext_tw_video_thumb/106301...</td>\n",
       "      <td>[5, 5, 5]</td>\n",
       "      <td>https://twitter.com/user/status/10630200488166...</td>\n",
       "      <td>My horses are retarded https://t.co/HYhqc6d5WN</td>\n",
       "      <td>[OtherHate, OtherHate, OtherHate]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108927368075374593</th>\n",
       "      <td>http://pbs.twimg.com/media/D2OzhzHUwAADQjd.jpg</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>https://twitter.com/user/status/11089273680753...</td>\n",
       "      <td>“NIGGA ON MA MOMMA YOUNGBOY BE SPITTING REAL S...</td>\n",
       "      <td>[NotHate, NotHate, NotHate]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114558534635618305</th>\n",
       "      <td>http://pbs.twimg.com/ext_tw_video_thumb/111401...</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>https://twitter.com/user/status/11145585346356...</td>\n",
       "      <td>RT xxSuGVNGxx: I ran into this HOLY NIGGA TODA...</td>\n",
       "      <td>[Racist, NotHate, NotHate]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035252480215592966</th>\n",
       "      <td>http://pbs.twimg.com/media/Dl30pGIU8AAVGxO.jpg</td>\n",
       "      <td>[1, 0, 1]</td>\n",
       "      <td>https://twitter.com/user/status/10352524802155...</td>\n",
       "      <td>“EVERYbody calling you Nigger now!” https://t....</td>\n",
       "      <td>[Racist, NotHate, Racist]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               img_url  \\\n",
       "1114679353714016256  http://pbs.twimg.com/tweet_video_thumb/D3gi9MH...   \n",
       "1063020048816660480  http://pbs.twimg.com/ext_tw_video_thumb/106301...   \n",
       "1108927368075374593     http://pbs.twimg.com/media/D2OzhzHUwAADQjd.jpg   \n",
       "1114558534635618305  http://pbs.twimg.com/ext_tw_video_thumb/111401...   \n",
       "1035252480215592966     http://pbs.twimg.com/media/Dl30pGIU8AAVGxO.jpg   \n",
       "\n",
       "                        labels  \\\n",
       "1114679353714016256  [4, 1, 3]   \n",
       "1063020048816660480  [5, 5, 5]   \n",
       "1108927368075374593  [0, 0, 0]   \n",
       "1114558534635618305  [1, 0, 0]   \n",
       "1035252480215592966  [1, 0, 1]   \n",
       "\n",
       "                                                             tweet_url  \\\n",
       "1114679353714016256  https://twitter.com/user/status/11146793537140...   \n",
       "1063020048816660480  https://twitter.com/user/status/10630200488166...   \n",
       "1108927368075374593  https://twitter.com/user/status/11089273680753...   \n",
       "1114558534635618305  https://twitter.com/user/status/11145585346356...   \n",
       "1035252480215592966  https://twitter.com/user/status/10352524802155...   \n",
       "\n",
       "                                                            tweet_text  \\\n",
       "1114679353714016256       @FriskDontMiss Nigga https://t.co/cAsaLWEpue   \n",
       "1063020048816660480     My horses are retarded https://t.co/HYhqc6d5WN   \n",
       "1108927368075374593  “NIGGA ON MA MOMMA YOUNGBOY BE SPITTING REAL S...   \n",
       "1114558534635618305  RT xxSuGVNGxx: I ran into this HOLY NIGGA TODA...   \n",
       "1035252480215592966  “EVERYbody calling you Nigger now!” https://t....   \n",
       "\n",
       "                                            labels_str  \n",
       "1114679353714016256      [Religion, Racist, Homophobe]  \n",
       "1063020048816660480  [OtherHate, OtherHate, OtherHate]  \n",
       "1108927368075374593        [NotHate, NotHate, NotHate]  \n",
       "1114558534635618305         [Racist, NotHate, NotHate]  \n",
       "1035252480215592966          [Racist, NotHate, Racist]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('../data/MMHS150K_GT.json', orient='index', convert_axes=False, convert_dates=False, keep_default_dates=False) #\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make 1 Column for Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = {0:0, 1:1, 2:1, 3:1, 4:1, 5:1}\n",
    "df['labels'] = df['labels'].apply(lambda x: [*map(dct.get, x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['majority_label'] = df.apply(lambda x: Counter(x['labels']).most_common()[0][0], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['img_url', 'tweet_url', 'labels_str', 'labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/11/29 14:42:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "\n",
    "MAX_MEMORY = \"5g\"\n",
    "spark = SparkSession.builder \\\n",
    "                    .appName('multi_class_text_classifiter')\\\n",
    "                    .config(\"spark.executor.memory\", MAX_MEMORY) \\\n",
    "                    .config(\"spark.driver.memory\", MAX_MEMORY) \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1114679353714016256            friskdontmiss nigga https t co casalwepue\n",
       "1063020048816660480         my horses are retarded https t co hyhqc6d5wn\n",
       "1108927368075374593    nigga on ma momma youngboy be spitting real sh...\n",
       "1114558534635618305    rt xxsugvngxx  i ran into this holy nigga toda...\n",
       "1035252480215592966    everybody calling you nigger now  https t co 6...\n",
       "                                             ...                        \n",
       "1114170734472048640    svdate  gtconway3d i would just say hes donny ...\n",
       "1110368198786846720    cheftime dev congrats my nigga keep on grindin...\n",
       "1106941858540851200            my nigga big shitty https t co e0snjgbgh9\n",
       "1105268309233188865    did she just say  my nigga  to rich   amp  she...\n",
       "1114653514364530691    this nigga joe budden said thanos got a galact...\n",
       "Name: tweet_text_clean, Length: 149823, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Diesen Abschnitt in eine Methode für Spark map auslagern.\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_text(x):\n",
    "    s = x.lower()\n",
    "    s = re.sub(r'[^A-Za-z0-9 ]+', ' ', s)\n",
    "    s = s.strip()\n",
    "    \n",
    "    return (s)\n",
    "\n",
    "df['tweet_text_clean'] = df['tweet_text'].apply(clean_text)\n",
    "df['tweet_text_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "\n",
    "# sqlContext = SQLContext(spark)\n",
    "df_small = df.sample(10000)\n",
    "cleaned_df = spark.createDataFrame(df_small) #sqlContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/11/29 14:45:25 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "22/11/29 14:45:25 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Word2Vec\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"tweet_text_clean\", outputCol=\"tokens\")\n",
    "w2v = Word2Vec(vectorSize=300, minCount=0, inputCol=\"tokens\", outputCol=\"features\")\n",
    "doc2vec_pipeline = Pipeline(stages=[tokenizer,w2v])\n",
    "doc2vec_model = doc2vec_pipeline.fit(cleaned_df)\n",
    "doc2vecs_df = doc2vec_model.transform(cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+--------------------+--------------------+--------------------+\n",
      "|          tweet_text|majority_label|    tweet_text_clean|              tokens|            features|\n",
      "+--------------------+--------------+--------------------+--------------------+--------------------+\n",
      "|Any movie with th...|             0|any movie with th...|[any, movie, with...|[0.00448822320686...|\n",
      "+--------------------+--------------+--------------------+--------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc2vecs_df.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_train_df, w2v_test_df = doc2vecs_df.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "rf_classifier = RandomForestClassifier(labelCol=\"majority_label\", featuresCol=\"features\")\n",
    "\n",
    "rf_classifier_pipeline = Pipeline(stages=[rf_classifier])\n",
    "rf_predictions = rf_classifier_pipeline.fit(w2v_train_df).transform(w2v_test_df)\n",
    "\n",
    "rf_model_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"majority_label\", predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.735917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "accuracy = rf_model_evaluator.evaluate(rf_predictions)\n",
    "print(\"Accuracy = %g\" % (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr_classifier = LogisticRegression(family=\"multinomial\", labelCol=\"majority_label\", featuresCol=\"features\")\n",
    "\n",
    "lr_classifier_pipeline = Pipeline(stages=[lr_classifier])\n",
    "lr_predictions = lr_classifier_pipeline.fit(w2v_train_df).transform(w2v_test_df)\n",
    "\n",
    "lr_model_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"majority_label\", predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.743152\n"
     ]
    }
   ],
   "source": [
    "accuracy = lr_model_evaluator.evaluate(lr_predictions)\n",
    "print(\"Accuracy = %g\" % (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|          tweet_text|majority_label|    tweet_text_clean|              tokens|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|\"Hoe ass nigga......|             0|hoe ass nigga  ht...|[hoe, ass, nigga,...|[-0.0088021091069...|[0.92616150267625...|[0.86439961978824...|       0.0|\n",
      "|#EntlekICantDealW...|             1|entlekicantdealwi...|[entlekicantdealw...|[-0.0099941235412...|[1.35508797753429...|[0.93762444011813...|       0.0|\n",
      "|#Ohio  Stop the d...|             0|ohio  stop the dr...|[ohio, , stop, th...|[-0.0476397339565...|[0.28989575573780...|[0.64101943171728...|       0.0|\n",
      "|#she loves this d...|             0|she loves this dr...|[she, loves, this...|[-0.0034911678218...|[0.94557109309661...|[0.86888570705586...|       0.0|\n",
      "|@AJEnglish This i...|             1|ajenglish this is...|[ajenglish, this,...|[-0.0016592609130...|[0.69888314002942...|[0.80182919166782...|       0.0|\n",
      "|@Acosta They are;...|             0|acosta they are  ...|[acosta, they, ar...|[-0.0229609268169...|[-0.2267181499515...|[0.38854406626429...|       1.0|\n",
      "|@Ale_Mussolini_ @...|             0|ale mussolini   j...|[ale, mussolini, ...|[-0.0260179142390...|[0.22552972230686...|[0.61089109685271...|       0.0|\n",
      "|@AnnCoulter Bring...|             0|anncoulter bring ...|[anncoulter, brin...|[-0.0211239207327...|[0.42079356421220...|[0.69879937826496...|       0.0|\n",
      "|@ArchKennedy @POT...|             0|archkennedy  potu...|[archkennedy, , p...|[-0.0312666160114...|[0.32398242926684...|[0.65655170176172...|       0.0|\n",
      "|@BCFMONEYMAN1 Tel...|             0|bcfmoneyman1 tell...|[bcfmoneyman1, te...|[0.00493156472536...|[0.54684371884262...|[0.74907545399656...|       0.0|\n",
      "+--------------------+--------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_predictions.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "28d6d9e31a694f2aba28d42b1019d9365f56410d563150feaee59905aa4508a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
